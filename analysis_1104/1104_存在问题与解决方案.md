# 荔枝霜疫霉预警阈值模型 - 存在问题与解决方案

## 文档说明
本文档针对代码审查中发现的问题，结合用户的实际需求，提出具体的解决方案。

---

## 问题1：数据合并统计信息不足

### 问题描述
当前代码在合并感染率数据与气象因子数据时，只输出了合并后的行数，没有详细的匹配统计信息，无法了解：
- 合并前各有多少行数据
- 有多少日期成功匹配
- 有多少日期因不匹配而丢失
- 丢失的具体日期是哪些

### 解决方案
**在数据合并时添加详细的统计信息输出：**

```python
# 合并前统计
met_count = len(met)
infection_count = len(infection)
met_unique_dates = met[met_date_col].nunique()
infection_unique_dates = infection[inf_date_col].nunique()

print(f"\n=== 数据合并统计 ===")
print(f"气象数据: {met_count} 行, {met_unique_dates} 个唯一日期")
print(f"感染数据: {infection_count} 行, {infection_unique_dates} 个唯一日期")

# 合并
df = pd.merge(met, infection[merge_cols], 
              left_on=met_date_col, right_on=inf_date_col, how="inner")

# 合并后统计
merged_count = len(df)
merged_unique_dates = df[met_date_col].nunique()

print(f"合并后: {merged_count} 行, {merged_unique_dates} 个唯一日期")

# 检查丢失情况
met_dates = set(met[met_date_col].dropna())
inf_dates = set(infection[inf_date_col].dropna())
merged_dates = set(df[met_date_col].dropna())

lost_met_dates = sorted(met_dates - merged_dates)
lost_inf_dates = sorted(inf_dates - merged_dates)

if lost_met_dates:
    print(f"\n警告: {len(lost_met_dates)} 个气象数据日期未匹配:")
    for date in lost_met_dates[:10]:  # 只显示前10个
        print(f"  - {date}")
    if len(lost_met_dates) > 10:
        print(f"  ... 还有 {len(lost_met_dates) - 10} 个")

if lost_inf_dates:
    print(f"\n警告: {len(lost_inf_dates)} 个感染数据日期未匹配:")
    for date in lost_inf_dates[:10]:  # 只显示前10个
        print(f"  - {date}")
    if len(lost_inf_dates) > 10:
        print(f"  ... 还有 {len(lost_inf_dates) - 10} 个")
```

---

## 问题2：异常值处理策略

### 问题描述
用户明确表示：**如果异常值不包括感染率有实际数据的天数，就不用管气象因子里的异常值**。

这意味着：
- 只需要检查**在感染率数据存在的日期里**，气象因子是否有异常值
- 如果那些日期没有异常值，就不需要处理
- 如果那些日期有异常值，需要处理

### 解决方案
**在数据合并后，只对合并后的数据（即有感染率数据的日期）检查和处理异常值：**

```python
# 合并数据
df = pd.merge(...)

# 只对合并后的数据检查异常值（即感染率数据存在的日期）
def check_merged_data_outliers(df: pd.DataFrame, feature_cols: List[str]) -> Dict:
    """检查合并后数据中的异常值（只检查有感染率数据的日期）"""
    outlier_info = {}
    
    for col in feature_cols:
        if col not in df.columns:
            continue
        
        # 检查负值
        negatives = df[col][df[col] < 0]
        if len(negatives) > 0:
            outlier_info[col] = {
                "负值数量": len(negatives),
                "负值日期": sorted(negatives.index.tolist()[:10]),  # 显示前10个日期
                "最小负值": float(negatives.min())
            }
    
    return outlier_info

# 检查异常值
outlier_info = check_merged_data_outliers(df, feature_cols)

if outlier_info:
    print("\n=== 合并数据中的异常值检查 ===")
    print("以下异常值存在于有感染率数据的日期中，需要处理：")
    for col, info in outlier_info.items():
        print(f"\n{col}:")
        print(f"  负值数量: {info['负值数量']}")
        print(f"  最小负值: {info['最小负值']}")
        if info['负值日期']:
            print(f"  包含负值的日期（前10个）: {info['负值日期']}")
    
    # 处理异常值（只处理有感染率数据的日期中的异常值）
    df = clean_outliers_for_merged_data(df, feature_cols)
else:
    print("\n✓ 合并数据中未发现异常值（在有感染率数据的日期中）")
```

---

## 问题3：缺失值检查 - 需要指出具体日期

### 问题描述
用户想知道：**存在感染率的天数里面，是否有气象数据缺失的天数？如果有，请指出是哪一天。**

### 解决方案
**在数据合并后，检查哪些日期有感染率数据但气象因子数据缺失：**

```python
# 合并数据后，检查缺失值
def check_missing_features_for_infection_dates(df: pd.DataFrame, feature_cols: List[str], date_col: str) -> Dict:
    """检查有感染率数据的日期中，哪些日期的气象因子缺失"""
    missing_info = {}
    
    # 对有感染率数据的每一行，检查特征是否缺失
    for idx, row in df.iterrows():
        date = row[date_col]
        missing_features = []
        
        for col in feature_cols:
            if col in row and (pd.isna(row[col]) or np.isnan(row[col])):
                missing_features.append(col)
        
        if missing_features:
            missing_info[date] = missing_features
    
    return missing_info

# 检查缺失值
missing_info = check_missing_features_for_infection_dates(df, feature_cols, met_date_col)

if missing_info:
    print("\n=== 有感染率数据的日期中，气象因子缺失情况 ===")
    print(f"发现 {len(missing_info)} 个日期存在气象因子缺失：")
    for date, missing_features in missing_info.items():
        print(f"\n日期: {date}")
        print(f"  缺失的特征: {', '.join(missing_features)}")
    
    # 保存到文件
    missing_report = []
    for date, missing_features in missing_info.items():
        missing_report.append({
            "日期": date,
            "缺失特征": ", ".join(missing_features),
            "缺失数量": len(missing_features)
        })
    
    df_missing = pd.DataFrame(missing_report)
    missing_file = os.path.join(out_dir, "缺失数据日期清单.csv")
    df_missing.to_csv(missing_file, index=False, encoding="utf-8-sig")
    print(f"\n已保存缺失数据日期清单: {missing_file}")
else:
    print("\n✓ 所有有感染率数据的日期，气象因子数据完整")
```

---

## 问题4：综合Pearson与GRA进行排序

### 问题描述
当前代码只按Pearson相关性绝对值排序，没有考虑GRA分数。

### 解决方案
**添加综合评分，同时考虑Pearson和GRA：**

```python
# 计算综合评分
df_score["综合评分"] = np.abs(df_score["pearson"]) * 0.5 + df_score["gra"] * 0.5

# 按综合评分排序
df_score = df_score.sort_values(by=["综合评分"], ascending=False)
```

---

## 问题5：不设置测试集与训练集

### 问题描述
用户表示当前数据量太少，不设置测试集与训练集，等以后数据量多了再进行这样的处理。

### 解决方案
**保持当前代码不变，不使用train_test_split，直接在所有数据上训练和评估。**

---

## 问题6：根据样本数量调整规则过滤条件

### 问题描述
当前规则过滤的阈值固定为50%，可能对小样本不够严格。

### 解决方案
**根据样本数量动态调整阈值：**

```python
# 根据样本数量调整阈值
if samples < 5:
    min_rate = 0.8  # 小样本需要更高准确率
elif samples < 10:
    min_rate = 0.7
elif samples < 20:
    min_rate = 0.6
else:
    min_rate = 0.5  # 大样本可以稍微放宽

if pred_class in warning_labels and pred_rate >= min_rate:
    # 添加规则
    all_rules[pred_class].append({...})
```

---

## 问题7：报告参数硬编码问题

### 问题描述
用户使用batch批处理代码，担心报告中的参数是否是硬编码的。

### 检查结果
检查 `scripts/analyze_thresholds_1104.py` 的 `generate_report` 函数，发现第498行确实硬编码了 `max_depth=3`。

### 解决方案
**修改generate_report函数，从results中获取实际参数：**

```python
def generate_report(results: dict, out_dir: str, max_depth: int = 3, min_samples_leaf: int = 5):
    """生成详细分析报告"""
    # ... 前面的代码 ...
    
    # 4. 方法概述
    report_lines.append("## 4. 方法概述\n\n")
    
    # 使用传入的实际参数，而不是硬编码
    report_lines.append(f"**决策树多分类（深度 max_depth={max_depth}, min_samples_leaf={min_samples_leaf}）**：使用预警等级（0-3级）作为目标变量，从多气象因子中提取每个预警等级的阈值组合规则。\n\n")
```

**同时修改run_analysis函数，将参数传递给generate_report：**

```python
def run_analysis(factors_xlsx: str, infection_xlsx: str, out_dir: str, max_depth: int = 3, min_samples_leaf: int = 5):
    # ... 分析代码 ...
    
    # 返回结果时包含参数
    return {
        "df": df,
        "feature_cols": feature_cols,
        "rules_by_level": all_rules,
        "feature_scores": feature_scores,
        "warning_labels": warning_labels,
        "max_depth": max_depth,  # 添加参数
        "min_samples_leaf": min_samples_leaf,  # 添加参数
        "stats": {
            "total_samples": len(df),
            "valid_samples": mask_valid.sum(),
            "warning_distribution": dict(warning_counts),
        }
    }
```

**在generate_report调用时传入参数：**

```python
# 在main函数或batch函数中
results = run_analysis(...)
generate_report(results, args.out, max_depth=args.max_depth, min_samples_leaf=args.min_samples_leaf)
```

---

## 问题8：样本数量变少的原因分析

### 问题描述
- `analysis_1104/1104.md` 显示：有效样本数 57 条
- `analysis_1104_batch/analysis_depth4_leaf2/1104.md` 显示：有效样本数 54 条
- 样本数量不一致

### 可能原因分析

需要检查以下几个环节：

1. **数据合并阶段**
   - 日期匹配是否一致
   - 是否有日期格式问题

2. **预警值转换阶段**
   - `_normalize_warning_level` 函数是否能正确识别所有预警值
   - 是否有"未定义"的样本被过滤

3. **特征缺失处理阶段**
   - 是否有特征缺失导致样本被删除
   - 不同运行时的特征列可能不同

### 解决方案
**添加详细的样本数量追踪日志：**

```python
# 在每个关键步骤后输出样本数量
print(f"\n=== 样本数量追踪 ===")
print(f"1. 合并后（未转换预警值）: {len(df)} 条")

# 转换预警值
df["预警数值"] = df[warning_col].map(_normalize_warning_level)
before_drop = len(df)
df = df.dropna(subset=["预警数值"])
after_drop = len(df)
print(f"2. 转换预警值后: {before_drop} -> {after_drop} 条（删除 {before_drop - after_drop} 条）")

# 检查删除的原因
dropped_samples = df[df[warning_col].map(_normalize_warning_level).isna()]
if len(dropped_samples) > 0:
    print(f"   删除的样本预警值: {dropped_samples[warning_col].unique().tolist()}")

# 特征缺失处理
mask_valid = ~np.isnan(X).any(axis=1)
before_valid = len(df)
after_valid = mask_valid.sum()
print(f"3. 特征缺失处理后: {before_valid} -> {after_valid} 条（删除 {before_valid - after_valid} 条）")

# 检查哪些特征导致样本被删除
if before_valid > after_valid:
    missing_by_feature = {}
    for col in feature_cols:
        missing_count = df[col].isna().sum()
        if missing_count > 0:
            missing_by_feature[col] = missing_count
    if missing_by_feature:
        print(f"   特征缺失情况:")
        for col, count in missing_by_feature.items():
            print(f"     {col}: {count} 个缺失值")
```

---

## 问题9：更新预警等级分类规则

### 问题描述
用户提供了新的数据格式和等级分类规则，需要调整代码逻辑。

### 新的数据格式分析

从用户提供的数据看：
1. **预警等级列**：包含 "0"、"轻度（不易发生）"、"中度（较易发生）"、"重度（易发生）"、"未定义"
2. **预警列**：包含 "0"、"1"、"2"、"3"、"未定义"
3. **2019年数据**：树上花果感染率都是"未做"，树下感染率有数据，但预警等级都是"未定义"
4. **2025年数据**：有一个日期错误（"2024年4月21日"应该是"2025年4月21日"）

### 新的分类规则

根据用户提供的数据，分类规则应该是：
- **0级（不发生）**：树上和树下感染率都为0%
- **1级（轻度）**：预警列值为"1"或预警等级为"轻度（不易发生）"
- **2级（中度）**：预警列值为"2"或预警等级为"中度（较易发生）"
- **3级（重度）**：预警列值为"3"或预警等级为"重度（易发生）"
- **未定义**：其他情况（如树上感染率为"未做"）

### 解决方案

**更新 `_normalize_warning_level` 函数：**

```python
def _normalize_warning_level(value) -> Optional[int]:
    """将预警值转换为数值：0, 1, 2, 3"""
    if value is None:
        return None
    
    s = str(value).strip()
    if s == "" or s.lower() == "nan":
        return None
    
    # 直接是数字 0, 1, 2, 3
    if s.isdigit():
        val = int(s)
        if 0 <= val <= 3:
            return val
    
    # 文字描述匹配（优先级从高到低）
    # 3级（重度）
    if "重度" in s or "3" in s or "易发生" in s:
        return 3
    
    # 2级（中度）
    if "中度" in s or "2" in s or "较易" in s:
        return 2
    
    # 1级（轻度）
    if "轻度" in s or "1" in s or "不易" in s:
        return 1
    
    # 0级（不发生）
    if "0" in s or "不发生" in s or "无" in s:
        return 0
    
    # 未定义
    return None
```

**更新 `_find_warning_column` 函数，优先查找"预警"列（数值列）：**

```python
def _find_warning_column(df: pd.DataFrame) -> Optional[str]:
    """识别预警列（优先找"预警"，不是"预警等级"）"""
    # 优先找精确匹配"预警"的列（不包含"等级"）
    exact_match = [c for c in df.columns if str(c).strip() == "预警"]
    if exact_match:
        return str(exact_match[0])
    
    # 其次找包含"预警"但不包含"等级"的列
    candidates = [c for c in df.columns 
                  if "预警" in str(c) and "等级" not in str(c)]
    if candidates:
        return str(candidates[0])
    
    # 最后找包含"预警"的列
    candidates = [c for c in df.columns if "预警" in str(c)]
    if candidates:
        return str(candidates[0])
    
    return None
```

**更新数据读取逻辑，处理"未做"的情况：**

```python
# 识别感病率列
down_col, up_col = _pick_infection_columns(infection)

# 处理"未做"的情况
if down_col:
    infection[down_col] = infection[down_col].replace(["未做", "未做", "未做%"], None)
if up_col:
    infection[up_col] = infection[up_col].replace(["未做", "未做", "未做%"], None)
```

---

## 实施计划

### 优先级1（立即实施）
1. ✅ 问题1：添加数据合并统计信息
2. ✅ 问题2：异常值处理策略（只处理有感染率数据的日期）
3. ✅ 问题3：缺失值检查并指出具体日期
4. ✅ 问题9：更新预警等级分类规则

### 优先级2（近期实施）
5. ✅ 问题4：综合Pearson与GRA排序
6. ✅ 问题6：根据样本数量调整规则过滤条件
7. ✅ 问题7：修复报告参数硬编码

### 优先级3（已完成/无需实施）
8. ✅ 问题5：不设置测试集（保持现状）
9. ✅ 问题8：样本数量变少原因分析（添加追踪日志）

---

## 注意事项

1. **数据质量检查**：在实施前，建议先运行数据质量检查脚本，确认当前数据状态
2. **向后兼容**：修改代码时，确保不影响已有的分析结果
3. **测试验证**：修改后，建议在小数据集上测试，确认逻辑正确
4. **文档更新**：修改代码后，更新相关文档说明

---

**文档生成时间**: 2024年11月

**下一步**: 等待用户确认方案后，开始实施代码修改。


